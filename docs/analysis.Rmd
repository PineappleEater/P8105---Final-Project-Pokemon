---
title: "Machine Learning & Statistical Analysis"
output:
  html_document:
    theme: cosmo
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    toc_depth: 2
    code_folding: hide
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)
library(factoextra)
library(FactoMineR)
library(cluster)
library(caret)
library(pROC)
library(randomForest)
library(rpart)
library(rpart.plot)
library(knitr)

set.seed(123)
theme_set(theme_minimal(base_size = 12))
```

```{r load-data, include=FALSE}
# Load final evolutions dataset
pokemon_df <- read_csv("../data/pokemon_data_final_evolutions_enriched.csv", show_col_types = FALSE)
```

# Overview

This page presents streamlined machine learning and statistical analyses of Pok√©mon data, including dimensionality reduction, clustering, and classification models.

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0;">
<div style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white;">
<div style="font-size: 2.5em; font-weight: bold;">742</div>
<div>Pok√©mon Analyzed</div>
</div>
<div style="padding: 20px; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); border-radius: 15px; color: white;">
<div style="font-size: 2.5em; font-weight: bold;">9</div>
<div>Features for PCA</div>
</div>
<div style="padding: 20px; background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); border-radius: 15px; color: white;">
<div style="font-size: 2.5em; font-weight: bold;">4</div>
<div>Optimal Clusters</div>
</div>
<div style="padding: 20px; background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); border-radius: 15px; color: white;">
<div style="font-size: 2.5em; font-weight: bold;">99.5%</div>
<div>Best Model AUC</div>
</div>
</div>

---

# PCA Analysis

## Dimensionality Reduction

Principal Component Analysis (PCA) reduces 9 numeric features (HP, Attack, Defense, Sp. Attack, Sp. Defense, Speed, Height, Weight, BMI) into uncorrelated principal components.

```{r pca-prep}
# Select numeric features
numeric_features <- c("hp", "attack", "defense", "sp_atk", "sp_def", "speed",
                     "height_m", "weight_kgs", "bmi")

# Prepare PCA dataset
pca_df <- pokemon_df %>%
  select(dex, name, category, generation, type_1, all_of(numeric_features)) %>%
  drop_na()

# Scale features
numeric_data <- pca_df %>% select(all_of(numeric_features))
scaled_data <- scale(numeric_data)
```

```{r pca-compute}
# Perform PCA
pca_result <- prcomp(scaled_data, center = FALSE, scale. = FALSE)

# Variance explained
variance_explained <- summary(pca_result)$importance
kable(variance_explained[, 1:5],
      caption = "Variance Explained by First 5 Principal Components",
      digits = 3)
```

## Variance Explained

```{r pca-scree, fig.height=5}
# Scree plot
fviz_eig(pca_result, addlabels = TRUE,
         main = "Scree Plot: Variance Explained by Each PC",
         barfill = "#667eea", barcolor = "#667eea") +
  theme_minimal(base_size = 12)
```

**Key Finding**: First 3 PCs explain ~70% of total variance, with PC1 capturing battle power (36%) and PC2 capturing physical size (21%).

## PCA Biplot

```{r pca-biplot, fig.width=10, fig.height=8}
# Add category info for coloring
pca_with_category <- pca_df %>%
  mutate(category = factor(category,
                          levels = c("Regular", "Legendary", "Mythical", "Paradox", "Ultra Beast")))

# Create biplot
fviz_pca_biplot(pca_result,
                geom.ind = "point",
                col.ind = pca_with_category$category,
                palette = c("Regular" = "#3498db",
                           "Legendary" = "#e74c3c",
                           "Mythical" = "#9b59b6",
                           "Paradox" = "#f39c12",
                           "Ultra Beast" = "#1abc9c"),
                addEllipses = FALSE,
                col.var = "black",
                repel = TRUE,
                title = "PCA Biplot: Pok√©mon in PC1-PC2 Space",
                legend.title = "Category") +
  theme_minimal(base_size = 12)
```

**Interpretation**:
- PC1 (horizontal): Battle effectiveness (stats correlate positively)
- PC2 (vertical): Physical dimensions (height/weight/BMI)
- Legendary Pok√©mon cluster toward high PC1 values

---

# K-Means Clustering

## Optimal Number of Clusters

```{r clustering-elbow, fig.height=5}
# Elbow method
fviz_nbclust(scaled_data, kmeans, method = "wss", k.max = 10) +
  geom_vline(xintercept = 4, linetype = 2, color = "red") +
  labs(title = "Elbow Method: Optimal Number of Clusters",
       subtitle = "Within-cluster sum of squares (WSS) vs. Number of Clusters") +
  theme_minimal(base_size = 12)
```

**Decision**: k=4 clusters selected based on elbow point.

## Cluster Visualization

```{r clustering-kmeans}
# Perform K-means with k=4
set.seed(123)
kmeans_result <- kmeans(scaled_data, centers = 4, nstart = 25)

# Add cluster assignments
pca_df$cluster <- as.factor(kmeans_result$cluster)
```

```{r clustering-viz, fig.width=10, fig.height=7}
# Visualize clusters in PCA space
fviz_cluster(kmeans_result, data = scaled_data,
             geom = "point",
             ellipse.type = "convex",
             palette = c("#e74c3c", "#3498db", "#2ecc71", "#f39c12"),
             ggtheme = theme_minimal(base_size = 12),
             main = "K-Means Clustering (k=4) in PCA Space")
```

## Cluster Profiles

```{r clustering-profiles}
# Calculate cluster statistics
cluster_summary <- pca_df %>%
  group_by(cluster) %>%
  summarise(
    Count = n(),
    `Avg BST` = round(mean(hp + attack + defense + sp_atk + sp_def + speed)),
    `% Legendary` = round(100 * mean(category %in% c("Legendary", "Mythical")), 1),
    `Avg Attack` = round(mean(attack)),
    `Avg Defense` = round(mean(defense)),
    `Avg Speed` = round(mean(speed)),
    .groups = "drop"
  ) %>%
  arrange(desc(`Avg BST`))

# Add descriptive labels
cluster_summary <- cluster_summary %>%
  mutate(Label = case_when(
    `Avg BST` >= 550 ~ "High-Power Sweepers",
    `Avg BST` >= 450 ~ "Balanced All-Rounders",
    `Avg BST` >= 400 ~ "Defensive Tanks",
    TRUE ~ "Early-Game / Weak"
  ))

kable(cluster_summary,
      caption = "Cluster Characteristics",
      align = "c")
```

**Cluster Insights**:

- **Cluster with highest BST**: Elite Pok√©mon (35%+ legendary rate)
- **Cluster with lowest BST**: Early-game Pok√©mon (0% legendary)
- Clear separation between competitive and casual Pok√©mon

---

# Classification Models

## Legendary Prediction

Binary classification task: predict `is_legendary` status based on stats and types.

```{r classification-prep}
# Select features
num_features <- c("hp", "attack", "defense", "sp_atk", "sp_def", "speed",
                  "height_m", "weight_kgs", "bmi")
type_features <- grep("^has_", names(pokemon_df), value = TRUE)
predictor_cols <- c(num_features, type_features)

# Prepare modeling dataset
model_df <- pokemon_df %>%
  select(all_of(c("is_legendary", predictor_cols))) %>%
  mutate(is_legendary = factor(is_legendary, levels = c(FALSE, TRUE),
                               labels = c("Regular", "Legendary"))) %>%
  drop_na()

# Train-test split (70-30)
set.seed(123)
train_index <- createDataPartition(model_df$is_legendary, p = 0.7, list = FALSE)
train_data <- model_df[train_index, ]
test_data <- model_df[-train_index, ]
```

## Model Training

```{r train-models, cache=TRUE}
# Training control
train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

# 1. Logistic Regression
logistic_model <- train(
  is_legendary ~ .,
  data = train_data,
  method = "glm",
  family = "binomial",
  trControl = train_control,
  metric = "ROC"
)

# 2. Decision Tree
tree_model <- train(
  is_legendary ~ .,
  data = train_data,
  method = "rpart",
  trControl = train_control,
  tuneLength = 10,
  metric = "ROC"
)

# 3. Random Forest (tuned)
rf_model <- train(
  is_legendary ~ .,
  data = train_data,
  method = "rf",
  trControl = train_control,
  tuneGrid = expand.grid(mtry = c(3, 5, 7, 10)),
  ntree = 500,
  metric = "ROC"
)
```

## Decision Tree Visualization

```{r tree-plot, fig.height=7}
rpart.plot(tree_model$finalModel,
           extra = 2,
           under = TRUE,
           box.palette = "RdYlGn",
           main = "Decision Tree for Legendary Classification")
```

## Model Comparison

```{r model-predictions}
# Generate predictions
logistic_pred <- predict(logistic_model, test_data, type = "prob")
tree_pred <- predict(tree_model, test_data, type = "prob")
rf_pred <- predict(rf_model, test_data, type = "prob")

# Calculate ROC curves
roc_logistic <- roc(test_data$is_legendary, logistic_pred$Legendary, quiet = TRUE)
roc_tree <- roc(test_data$is_legendary, tree_pred$Legendary, quiet = TRUE)
roc_rf <- roc(test_data$is_legendary, rf_pred$Legendary, quiet = TRUE)
```

```{r roc-plot, fig.height=6}
# Plot ROC curves
plot(roc_logistic, col = "#3498db", lwd = 2,
     main = "ROC Curves: Model Comparison")
plot(roc_tree, col = "#2ecc71", lwd = 2, add = TRUE)
plot(roc_rf, col = "#e74c3c", lwd = 2, add = TRUE)
legend("bottomright",
       legend = c(
         sprintf("Logistic Regression (AUC = %.3f)", auc(roc_logistic)),
         sprintf("Decision Tree (AUC = %.3f)", auc(roc_tree)),
         sprintf("Random Forest (AUC = %.3f)", auc(roc_rf))
       ),
       col = c("#3498db", "#2ecc71", "#e74c3c"),
       lwd = 2, bty = "n")
```

## Performance Metrics

```{r performance-table}
# Generate class predictions
logistic_class <- predict(logistic_model, test_data)
tree_class <- predict(tree_model, test_data)
rf_class <- predict(rf_model, test_data)

# Confusion matrices
logistic_cm <- confusionMatrix(logistic_class, test_data$is_legendary, positive = "Legendary")
tree_cm <- confusionMatrix(tree_class, test_data$is_legendary, positive = "Legendary")
rf_cm <- confusionMatrix(rf_class, test_data$is_legendary, positive = "Legendary")

# Summary table
performance_df <- data.frame(
  Model = c("Logistic Regression", "Decision Tree", "Random Forest"),
  AUC = c(auc(roc_logistic), auc(roc_tree), auc(roc_rf)),
  Accuracy = c(logistic_cm$overall["Accuracy"],
               tree_cm$overall["Accuracy"],
               rf_cm$overall["Accuracy"]),
  Sensitivity = c(logistic_cm$byClass["Sensitivity"],
                 tree_cm$byClass["Sensitivity"],
                 rf_cm$byClass["Sensitivity"]),
  Specificity = c(logistic_cm$byClass["Specificity"],
                 tree_cm$byClass["Specificity"],
                 rf_cm$byClass["Specificity"]),
  F1 = c(logistic_cm$byClass["F1"],
         tree_cm$byClass["F1"],
         rf_cm$byClass["F1"])
) %>%
  mutate(across(where(is.numeric), ~round(.x, 3)))

kable(performance_df,
      caption = "Classification Model Performance on Test Set",
      align = "lcccccc")
```

## Feature Importance

```{r feature-importance, fig.height=7}
# Random Forest variable importance
rf_imp <- varImp(rf_model)
plot(rf_imp, top = 15,
     main = "Top 15 Features: Random Forest Importance",
     col = "#667eea")
```

**Key Findings**:

- **Best Model**: Random Forest achieves 99.5% AUC with excellent recall
- **Top Predictors**: Total stats, Attack, Sp. Attack, Speed, HP
- **Type Features**: Dragon and Psychic types are strong legendary indicators
- **Perfect Separation**: Legendary Pok√©mon are statistically distinct (BST threshold ~580)

---

# Summary

<div style="background: #f8f9fa; padding: 30px; border-radius: 15px; border-left: 5px solid #667eea;">

### üìä PCA Results
- First 3 components capture ~70% of variance
- PC1 represents battle effectiveness, PC2 represents physical size
- Legendary Pok√©mon clearly separated in principal component space

### üéØ Clustering Results
- 4 distinct archetypes identified
- Elite tier (high BST, 35% legendary) vs casual tier (low BST, 0% legendary)
- Balanced distribution across defensive, balanced, and offensive clusters

### ü§ñ Classification Results
- Random Forest achieves 99.5% AUC (near-perfect classification)
- Legendary Pok√©mon are 99% separable by base stats alone
- Total BST is the single most important feature

</div>

---

<div style="text-align: center; padding: 20px; color: #666;">
All models trained on final evolution Pok√©mon only (n=742) to eliminate evolutionary stage bias
</div>
